{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8969fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2ef7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataBase:\n",
    "    \"\"\" Data base class API: loads, preprocesses, and tokenizes datasets to \n",
    "        be ready for the BERT model.\n",
    "        Required attributes:\n",
    "         - num_classes: number of classes in a dataset\n",
    "         - datasets: dictionary with 'train' and 'val' tokenized datasets;\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.num_classes: int\n",
    "        self.datasets: Dict[str, Dataset] = {}  \n",
    "        \n",
    "        \n",
    "class IMDb(ClassificationDataBase):\n",
    "    def __init__(self, device, backbone_name, **kwargs):\n",
    "        super().__init__()\n",
    "        loading_kwargs = {'path': 'imdb', \n",
    "                          'train_filename': 'train.tsv',\n",
    "                          'dev_filename': 'dev.tsv',\n",
    "                          'header': 0,\n",
    "                          'index_col': 0}\n",
    "        self.device = device\n",
    "        self._prepare_datasets(loading_kwargs, device, backbone_name)\n",
    "    \n",
    "    def _prepare_datasets(self, loading_kwargs, device, backbone_name):\n",
    "        dataframes = load_dataframes(loading_kwargs)\n",
    "        self.num_classes = len(dataframes['train']['label'].unique())\n",
    "        data_X, data_y = {}, {}\n",
    "        for split in dataframes.keys():\n",
    "            data_X[split] = dataframes[split].drop('label', axis=1, inplace=False)\n",
    "            data_X[split] = data_X[split].values.tolist()\n",
    "            data_y[split] = dataframes[split]['label'].values\n",
    "            data_y[split] = torch.LongTensor(data_y[split]).to(device)\n",
    "            data_X[split] = get_tokens(data_X[split], backbone_name=backbone_name)\n",
    "            data_X[split] = {k: v.to(device) for k,v in data_X[split].items()}\n",
    "            self.datasets[split] = TokenizedDataset(data_X[split], data_y[split])\n",
    "        \n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "            \n",
    "    def __getitem__(self,idx):\n",
    "        return {key: self.X[key][idx] for key in self.X.keys()}, self.y[idx]\n",
    "\n",
    "\n",
    "def get_all_subclasses(cls):\n",
    "    all_subclasses = []\n",
    "    for subclass in cls.__subclasses__():\n",
    "        all_subclasses.append(subclass)\n",
    "        all_subclasses.extend(get_all_subclasses(subclass))\n",
    "    return all_subclasses\n",
    "\n",
    "\n",
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "def load_dataframes(loading_kwargs):\n",
    "    path = loading_kwargs['path']\n",
    "    train_filename = loading_kwargs['train_filename']\n",
    "    dev_filename = loading_kwargs['dev_filename']\n",
    "    header = loading_kwargs['header']\n",
    "    index_col = loading_kwargs['index_col']\n",
    "    assert '.' in train_filename, f\"unrecognized file format {train_filename}\"\n",
    "    extension = train_filename.split('.')[-1]\n",
    "    if extension == 'tsv':\n",
    "        delimiter = '\\t'\n",
    "    elif extension == 'csv':\n",
    "        delimiter = ','\n",
    "    else:\n",
    "        raise ValueError(f\"unrecognized file format {extension}\")\n",
    "    dataframes = {}\n",
    "    for split,split_filename in zip(['train','dev'], [train_filename, dev_filename]):\n",
    "        filename = os.path.join(path, split_filename)\n",
    "        dataframes[split] = pd.read_csv(\n",
    "                filename,\n",
    "                delimiter=delimiter,\n",
    "                header=header,\n",
    "                index_col=index_col,\n",
    "                engine=\"python\",\n",
    "                error_bad_lines=False,\n",
    "                warn_bad_lines=False)\n",
    "        new_columns = [f\"sentence_{i}\" for i in range(len(dataframes[split].columns)-1)]+[\"label\"]\n",
    "        dataframes[split].columns = new_columns\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "def get_tokens(data_X: List[List[str]], backbone_name: str) -> dict:\n",
    "    tokenizer =  BertTokenizer.from_pretrained(backbone_name)\n",
    "    if len(data_X[0])==1:\n",
    "        data_X = [X[0] for X in data_X]\n",
    "    data_X = tokenizer.batch_encode_plus(\n",
    "                data_X,\n",
    "                add_special_tokens=True,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\")\n",
    "    return data_X\n",
    "    \n",
    "\n",
    "def stabilized_forward(linearized_encoder,\n",
    "            min_=1e-1,\n",
    "            max_=1e5,\n",
    "            scaler=1e3,\n",
    "            max_attempts=10):\n",
    "    def forward(x):\n",
    "        for i in range(len(linearized_encoder.layer)):\n",
    "            attempts = 0\n",
    "            prelim_x = linearized_encoder.layer[i](x)[0]\n",
    "            while torch.mean(torch.abs(prelim_x))>max_ and attempts<max_attempts:\n",
    "                for m in linearized_encoder.layer[i].modules():\n",
    "                    if isinstance(m, torch.nn.Linear):\n",
    "                        m.weight.data = m.weight.data/scaler\n",
    "                prelim_x = linearized_encoder.layer[i](x)[0]\n",
    "                attempts+=1\n",
    "            while torch.mean(torch.abs(prelim_x))<min_ and attempts<max_attempts:\n",
    "                for m in linearized_encoder.layer[i].modules():\n",
    "                    if isinstance(m, torch.nn.Linear):\n",
    "                        m.weight.data = scaler*m.weight.data\n",
    "                prelim_x = linearized_encoder.layer[i](x)[0]\n",
    "                attempts+=1\n",
    "            assert attempts<max_attempts\n",
    "            x = prelim_x\n",
    "        return x\n",
    "    return forward\n",
    "\n",
    "\n",
    "def max_pooling(token_embeddings, attention_mask):\n",
    "    input_mask_expanded=(attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float())\n",
    "    token_embeddings[input_mask_expanded == 0] = -1e9\n",
    "    return torch.max(token_embeddings, -2).values\n",
    "\n",
    "\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    input_mask_expanded=(attention_mask.unsqueeze(-1).float())\n",
    "    sum_embeddings=torch.sum(token_embeddings * input_mask_expanded, -2)\n",
    "    sum_mask=torch.clamp(input_mask_expanded.sum(-2), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def pool(x, encoded_input, pool_type):\n",
    "    if pool_type in ['avg', 'mean']:\n",
    "        x = mean_pooling(x['last_hidden_state'], encoded_input['attention_mask'])\n",
    "    elif pool_type == 'max':\n",
    "        x = max_pooling(x['last_hidden_state'], encoded_input['attention_mask'])\n",
    "    elif pool_type in ['cls', 'first']:\n",
    "        x = x['last_hidden_state'][:,0]\n",
    "    elif pool_type == 'pooler_output':\n",
    "        x = x['pooler_output']\n",
    "    else:\n",
    "        raise ValueError(f'unknown pool type {pool_type}.')\n",
    "    return x\n",
    "\n",
    "\n",
    "class BertSelfAttentionLinearized(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = torch.nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = torch.nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = torch.nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            self.max_position_embeddings = config.max_position_embeddings\n",
    "            self.distance_embedding = torch.nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
    "\n",
    "        self.is_decoder = config.is_decoder\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "\n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "        is_cross_attention = encoder_hidden_states is not None\n",
    "\n",
    "        if is_cross_attention and past_key_value is not None:\n",
    "            # reuse k,v, cross_attentions\n",
    "            key_layer = past_key_value[0]\n",
    "            value_layer = past_key_value[1]\n",
    "            attention_mask = encoder_attention_mask\n",
    "        elif is_cross_attention:\n",
    "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
    "            attention_mask = encoder_attention_mask\n",
    "        elif past_key_value is not None:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
    "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
    "        else:\n",
    "            key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "            value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "\n",
    "        if self.is_decoder:\n",
    "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
    "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
    "            # key/value_states (first \"if\" case)\n",
    "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
    "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
    "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
    "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
    "            past_key_value = (key_layer, value_layer)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            seq_length = hidden_states.size()[1]\n",
    "            position_ids_l = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
    "            position_ids_r = torch.arange(seq_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
    "            distance = position_ids_l - position_ids_r\n",
    "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
    "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
    "\n",
    "            if self.position_embedding_type == \"relative_key\":\n",
    "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores\n",
    "            elif self.position_embedding_type == \"relative_key_query\":\n",
    "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
    "\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        # attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        attention_probs = attention_scores\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "\n",
    "        if self.is_decoder:\n",
    "            outputs = outputs + (past_key_value,)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class ClassificationModelBase(torch.nn.Module):\n",
    "    \"\"\" The base model API\n",
    "        Required attributes:\n",
    "         - masks: dictionary storing lists of binary masks for\n",
    "           each stage ('embeddings', 'encoder', 'classifier')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.masks: Dict[str, List[torch.Tensor]]\n",
    "\n",
    "    def forward(self, X: Dict) -> torch.Tensor:\n",
    "        \"\"\" Forward pass of the model\n",
    "            Args:\n",
    "             - X: dictionary of batched tokenized documents\n",
    "            Returns: class logits\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(f\"override 'forward' method\")\n",
    "    \n",
    "\n",
    "class PrunerBase:\n",
    "    \"\"\" Pruner base class\n",
    "    \"\"\"\n",
    "\n",
    "    def prune(self, model: ClassificationModelBase,\n",
    "                    target_sparsity: float,\n",
    "                    pruning_type: str, **kwargs) -> List[torch.Tensor]:\n",
    "        \"\"\" Prune model\n",
    "            Args:\n",
    "             - model: model to prune;\n",
    "             - target_saprsity: desired sparsity of the model;\n",
    "             - pruning_type: 'effective' or 'direct.\n",
    "            Returns:\n",
    "             - list of binary tensors (masks)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"override prune method\")\n",
    "        \n",
    "        \n",
    "def random_pruning(sparsities, shapes, pruning_type='direct'):\n",
    "    masks = []\n",
    "    for shape, sparsity in zip(shapes, sparsities):\n",
    "        count = int(torch.prod(shape))\n",
    "        mask = torch.ones(count)\n",
    "        idx_to_prune = np.random.choice(range(count),\n",
    "                size=int(sparsity*count),\n",
    "                replace=False)\n",
    "        mask[idx_to_prune] = 0.\n",
    "        shape = tuple(int(dim) for dim in shape)\n",
    "        mask = mask.reshape(shape)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "\n",
    "def score_pruning(target_sparsity, scores, pruning_type):\n",
    "    scores_flatten = np.concatenate([score.reshape(-1) for score in scores])\n",
    "    threshold = np.quantile(scores_flatten, target_sparsity)\n",
    "    masks = [(score>threshold).float() for score in scores]\n",
    "    return masks\n",
    "\n",
    "\n",
    "class SNIP(PrunerBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def prune(self, model, target_sparsity, pruning_type, sample, batch_size=256, **kwargs):\n",
    "        model.eval()\n",
    "        weights = []\n",
    "        for module in model.get_prunable_modules:\n",
    "            weights.append(model.weight.data.detach().cpu())\n",
    "        batch_size = min(batch_size, len(sample))\n",
    "        dataloader = DataLoader(sample, batch_size=batch_size)\n",
    "        gradients = []\n",
    "        for i,(X,y) in enumerate(dataloader):\n",
    "            output = model(X)\n",
    "            loss = F.cross_entropy(output, y)\n",
    "            loss.backward(retain_graph=False)\n",
    "            for module in model.get_prunable_models:\n",
    "                curr_layer_grad = module.weight.grad.detach().cpu()\n",
    "                if i==0:\n",
    "                    gradients.append(curr_layer_grad)\n",
    "                else:\n",
    "                    sum_ = gradients[curr_layer_idx]*i\n",
    "                    avg_ = (sum_+curr_layer_grad)/(i+1)\n",
    "                    gradients[curr_layer_idx] = avg_\n",
    "                module.weight.grad = None\n",
    "        scores = [gradient*weight for gradient,weight in zip(gradients, weights)]\n",
    "        masks = score_pruning(target_sparsity, scores, pruning_type)\n",
    "        return masks\n",
    "\n",
    "\n",
    "class Magnitude(PrunerBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def prune(self, model, target_sparsity, pruning_type, **kwargs):\n",
    "        if pruning_type=='direct':\n",
    "            scores = self.scores(model)\n",
    "            return score_pruning(target_sparsity, scores)\n",
    "        \n",
    "    def scores(self, model):\n",
    "        scores = []\n",
    "        for module in model.get_prunable_modules:\n",
    "            scores.append(torch.abs(module.weight.data.detach()).numpy())\n",
    "        return scores\n",
    "\n",
    "    \n",
    "class RandomUniform(PrunerBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def prune(self, model, target_sparsity, pruning_type, **kwargs):\n",
    "        shapes = []\n",
    "        for module in model.get_prunable_modules:\n",
    "            shape = list(module.weight.data.detach().detach().numpy().shape)\n",
    "            shapes.append(torch.Tensor(shape))\n",
    "        if pruning_type=='direct':\n",
    "            sparsities = self.quotas(target_sparsity, shapes)\n",
    "            return random_pruning(sparsities, shapes)\n",
    "    \n",
    "    def quotas(self, target_sparsity, shapes):\n",
    "        return [target_sparsity]*len(shapes)\n",
    "    \n",
    "    \n",
    "class RandomIGQ(PrunerBase):\n",
    "    def __init__(self, tolerance=1e20):\n",
    "        super().__init__()\n",
    "\n",
    "    def prune(self, model, target_sparsity, pruning_type, **kwargs):\n",
    "        shapes = []\n",
    "        for module in model.get_prunable_modules:\n",
    "            shape = list(module.weight.data.detach().detach().numpy().shape)\n",
    "            shapes.append(torch.Tensor(shape))\n",
    "        if pruning_type=='direct':\n",
    "            sparsities = self.quotas(target_sparsity, shapes)\n",
    "            return random_pruning(sparsities, shapes)\n",
    "\n",
    "    def _bs_force_igq(self, areas, Lengths, target_sparsity, tolerance,f_low,f_high, depth):\n",
    "        lengths_low=[Length/(f_low/area+1) for Length,area in zip(Lengths,areas)]\n",
    "        overall_sparsity_low=1-sum(lengths_low)/sum(Lengths)\n",
    "        if abs(overall_sparsity_low-target_sparsity)<tolerance or depth<0:\n",
    "            return [1-length/Length for length,Length in zip(lengths_low,Lengths)]\n",
    "        lengths_high=[Length/(f_high/area+1) for Length,area in zip(Lengths,areas)]\n",
    "        overall_sparsity_high=1-sum(lengths_high)/sum(Lengths)\n",
    "        if abs(overall_sparsity_high-target_sparsity)<tolerance or depth<0:\n",
    "            return [1-length/Length for length,Length in zip(lengths_high,Lengths)]\n",
    "        force=float(f_low+f_high)/2\n",
    "        lengths=[Length/(force/area+1) for Length,area in zip(Lengths,areas)]\n",
    "        overall_sparsity=1-sum(lengths)/sum(Lengths)\n",
    "        f_low=force if overall_sparsity<target_sparsity else f_low\n",
    "        f_high=force if overall_sparsity>target_sparsity else f_high\n",
    "        return self._bs_force_igq(areas,Lengths,target_sparsity,tolerance,f_low,f_high, depth-1)\n",
    "\n",
    "    def quotas(self, target_sparsity, shapes):\n",
    "        counts=[torch.prod(shape) for shape in shapes]\n",
    "        tolerance=100./sum(counts)\n",
    "        areas=[1./count for count in counts]\n",
    "        Lengths=[count for count in counts]\n",
    "        return self._bs_force_igq(areas,Lengths,target_sparsity,tolerance,0,1e30, 1000)\n",
    "\n",
    "\n",
    "    def effective_masks(self, **kwargs) -> Dict[str, List[torch.Tensor]]:\n",
    "        \"\"\" Return effective masks in a dictionary by module:\n",
    "            'embeddings', 'encoder', 'classifier'\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(f\"override 'linearize' method\")\n",
    "        \n",
    "\n",
    "class LinearizedEmbeddings(torch.nn.Module):\n",
    "    def __init__(self, bert_embeddings):\n",
    "        super().__init__()\n",
    "        self.shapes = {1: bert_embeddings.word_embeddings.weight.data.size(),\n",
    "                2: bert_embeddings.position_embeddings.weight.data.size(),\n",
    "                3: bert_embeddings.token_type_embeddings.weight.data.size()}\n",
    "        self.total_length = sum(shape[0] for shape in self.shapes.values())\n",
    "        bert_word_embeddings = bert_embeddings.word_embeddings.weight.data.detach().clone().t()\n",
    "        self.word_embeddings = torch.nn.Linear(self.shapes[1][0],\n",
    "                self.shapes[1][1], bias=False)\n",
    "        self.word_embeddings.weight.data = bert_word_embeddings.requires_grad_(True)\n",
    "        bert_position_embeddings = bert_embeddings.position_embeddings.weight.data.detach().clone().t()\n",
    "        self.position_embeddings = torch.nn.Linear(self.shapes[2][0],\n",
    "                self.shapes[2][1], bias=False)\n",
    "        self.position_embeddings.weight.data = bert_position_embeddings.requires_grad_(True)\n",
    "        bert_token_type_embeddings = bert_embeddings.token_type_embeddings.weight.data.detach().clone().t()\n",
    "        self.token_type_embeddings = torch.nn.Linear(self.shapes[3][0],\n",
    "                self.shapes[3][1], bias=False)\n",
    "        self.token_type_embeddings.weight.data = bert_token_type_embeddings.requires_grad_(True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = torch.squeeze(X)\n",
    "        X1 = X[:, sum(self.shapes[i][0] for i in range(1,1)):sum(self.shapes[i][0] for i in range(1,2))]\n",
    "        X2 = X[:, sum(self.shapes[i][0] for i in range(1,2)):sum(self.shapes[i][0] for i in range(1,3))]\n",
    "        X3 = X[:, sum(self.shapes[i][0] for i in range(1,3)):sum(self.shapes[i][0] for i in range(1,4))]\n",
    "        word_out = self.word_embeddings(X1)\n",
    "        position_out = self.position_embeddings(X2)\n",
    "        token_type_out = self.token_type_embeddings(X3)\n",
    "        return word_out + position_out + token_type_out\n",
    "\n",
    "\n",
    "class LinearizedBERTClassifier(ClassificationModelBase):\n",
    "    def __init__(self, reference_model, stabilize=False):\n",
    "        super().__init__()\n",
    "        self.device = reference_model.device\n",
    "        self.stabilize = stabilize\n",
    "        config = BertConfig(hidden_act=lambda x: x,\n",
    "                hidden_dropout_prob=0,\n",
    "                attention_probs_dropout_prob=0)\n",
    "        linearized_encoder = BertModel(config).encoder\n",
    "        for layer in linearized_encoder.layer:\n",
    "            layer.attention.self = BertSelfAttentionLinearized(config)\n",
    "        if stabilize:\n",
    "            linearized_encoder.forward = stabilized_forward(linearized_encoder)\n",
    "        identity = torch.nn.Identity()\n",
    "        weights = []\n",
    "        for m in reference_model.module_list[1].modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                weights.append(m.weight.data.detach().clone())\n",
    "        idx = 0\n",
    "        for m in linearized_encoder.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                m.weight.data = weights[idx].requires_grad_(True)\n",
    "                idx+=1\n",
    "            if isinstance(m, torch.nn.LayerNorm):\n",
    "                m.forward = identity.forward\n",
    "        linearized_embeddings = LinearizedEmbeddings(reference_model.module_list[0])\n",
    "        self.total_length = linearized_embeddings.total_length\n",
    "        self.modules_list = torch.nn.ModuleList([\n",
    "                linearized_embeddings.to(self.device),\n",
    "                linearized_encoder.to(self.device),\n",
    "                #deepcopy(reference_model.modules_dict.classifier).to(self.device)])\n",
    "        for m in self.modules():\n",
    "            if hasattr(m, 'weight'):\n",
    "                m.weight.data = torch.abs(m.weight.data)\n",
    "                m.weight.grad = None\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x = self.module_list[0](inp)[None, :, :]\n",
    "        x = self.module_list[1](x)\n",
    "        mask = {'attention_mask': torch.ones(512)}\n",
    "        if self.stabilize:\n",
    "            x = {'last_hidden_state': x}\n",
    "        x = pool(x, mask, 'mean')\n",
    "        #x = self.modules_dict['classifier'](x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def layer_sparsity(mask: torch.Tensor):\n",
    "    return 1-torch.sum(mask>0)/np.prod(mask.numpy().shape)\n",
    "\n",
    "\n",
    "def model_sparsity(masks: List[torch.Tensor]):\n",
    "    counts = [np.prod(mask.numpy().shape) for mask in masks]\n",
    "    sparsities = [layer_sparsity(mask) for mask in masks]\n",
    "    active_parameters = 0\n",
    "    for count,sparsity in zip(counts, sparsities):\n",
    "        active_parameters+=count*(1-sparsity)\n",
    "    return 1-active_parameters/sum(counts)\n",
    "\n",
    "\n",
    "class BackboneBERT(ClassificationModelBase):\n",
    "    def __init__(self, backbone_name,\n",
    "                    pool_type,\n",
    "                    num_classes,\n",
    "                    device,\n",
    "                    **kwargs):\n",
    "        super().__init__()\n",
    "        self.pool_type = pool_type\n",
    "        bert = BertModel.from_pretrained(backbone_name)\n",
    "        classifier = torch.nn.Linear(768, num_classes, bias=True)\n",
    "        self.module_list = torch.nn.ModuleList([\n",
    "                bert.embeddings.to(device),\n",
    "                bert.encoder.to(device)])\n",
    "        self.prunable_modules = {torch.nn.Embedding, torch.nn.Linear}\n",
    "        self.create_masks()\n",
    "        self.device = device\n",
    "        \n",
    "    def get_prunable_modules(self):\n",
    "        prunable_modules = []\n",
    "        for module in self.module_list:\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, torch.nn.Embedding):\n",
    "                    prunable_modules.append(m)\n",
    "                if isinstance(m, torch.nn.Linear):\n",
    "                    prunable_modules.append(m)\n",
    "        return prunable_modules\n",
    "        \n",
    "    def create_masks(self):\n",
    "        self.masks = []\n",
    "        for module in self.get_prunable_modules():\n",
    "            self.masks.append(torch.ones(module.weight.data.size()))\n",
    "    \n",
    "    def update_masks(self, masks):\n",
    "        self.masks = masks\n",
    "\n",
    "    def apply_masks(self):\n",
    "        for i,module in enumerate(self.get_prunable_modules):\n",
    "            masked_weight = torch.mul(m.weight.data, self.masks[i])\n",
    "            m.weight.data = masked_weight\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        self.apply_masks()\n",
    "        attention_mask = inp['attention_mask'][:, None, None, :]\n",
    "        x = self.module_list[0](inp['input_ids'])\n",
    "        x = self.module_list[1](x, attention_mask=attention_mask)\n",
    "        x = pool(x, inp, self.pool_type)\n",
    "        #x = self.modules_dict['classifier'](x)\n",
    "        return x\n",
    "\n",
    "    def linearize(self):\n",
    "        self.apply_masks()\n",
    "        return LinearizedBERTClassifier(self, stabilize=True)\n",
    "    \n",
    "    @property\n",
    "    def effective_masks(self):\n",
    "        self.apply_masks()\n",
    "        linearized = self.linearize()\n",
    "        full_length = linearized.total_length\n",
    "        X = torch.ones((512,full_length))\n",
    "        output = torch.sum(linearized(X))\n",
    "        output.backward()\n",
    "        effective_masks = []\n",
    "        for module in self.get_prunable_modules:\n",
    "            scores = torch.abs(torch.mul(m.weight.grad,m.weight.data))\n",
    "            effective_masks.append((scores>0).int())\n",
    "        del linearized\n",
    "        return effective_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6d1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "imdb_dataset = IMDb(torch.device('cpu'), 'bert-base-uncased')\n",
    "sample = Subset(imdb_dataset.datasets['train'], range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "814ce0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "direct sparsity: 0.999000013\n",
      "effective sparsity: 0.999262094\n"
     ]
    }
   ],
   "source": [
    "model = BERTClassifier('bert-base-uncased', 'mean', 2, torch.device('cpu'))\n",
    "pruner = SNIP()\n",
    "masks=pruner.prune(model, 0.999, 'direct', sample)\n",
    "model.update_masks(masks)\n",
    "effective_masks = model.effective_masks()\n",
    "print(f'direct sparsity: {model_sparsity(masks):.9f}')\n",
    "print(f'effective sparsity: {model_sparsity(effective_masks):.9f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f45724f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.9999)\n",
      "1 tensor(0.9995)\n",
      "2 tensor(0.8483)\n",
      "3 tensor(0.9997)\n",
      "4 tensor(0.9998)\n",
      "5 tensor(0.9982)\n",
      "6 tensor(0.9974)\n",
      "7 tensor(0.9992)\n",
      "8 tensor(0.9991)\n",
      "9 tensor(0.9991)\n",
      "10 tensor(0.9995)\n",
      "11 tensor(0.9984)\n",
      "12 tensor(0.9974)\n",
      "13 tensor(0.9990)\n",
      "14 tensor(0.9996)\n",
      "15 tensor(0.9981)\n",
      "16 tensor(0.9981)\n",
      "17 tensor(0.9987)\n",
      "18 tensor(0.9986)\n",
      "19 tensor(0.9993)\n",
      "20 tensor(0.9997)\n",
      "21 tensor(0.9990)\n",
      "22 tensor(0.9979)\n",
      "23 tensor(0.9978)\n",
      "24 tensor(0.9980)\n",
      "25 tensor(0.9994)\n",
      "26 tensor(0.9999)\n",
      "27 tensor(0.9997)\n",
      "28 tensor(0.9996)\n",
      "29 tensor(0.9972)\n",
      "30 tensor(0.9981)\n",
      "31 tensor(0.9995)\n",
      "32 tensor(0.9998)\n",
      "33 tensor(0.9997)\n",
      "34 tensor(0.9996)\n",
      "35 tensor(0.9988)\n",
      "36 tensor(0.9990)\n",
      "37 tensor(0.9995)\n",
      "38 tensor(0.9998)\n",
      "39 tensor(0.9996)\n",
      "40 tensor(0.9993)\n",
      "41 tensor(0.9981)\n",
      "42 tensor(0.9990)\n",
      "43 tensor(0.9994)\n",
      "44 tensor(0.9998)\n",
      "45 tensor(0.9998)\n",
      "46 tensor(0.9996)\n",
      "47 tensor(0.9981)\n",
      "48 tensor(0.9984)\n",
      "49 tensor(0.9992)\n",
      "50 tensor(0.9996)\n",
      "51 tensor(0.9996)\n",
      "52 tensor(0.9993)\n",
      "53 tensor(0.9939)\n",
      "54 tensor(0.9938)\n",
      "55 tensor(0.9991)\n",
      "56 tensor(0.9995)\n",
      "57 tensor(0.9990)\n",
      "58 tensor(0.9982)\n",
      "59 tensor(0.9901)\n",
      "60 tensor(0.9904)\n",
      "61 tensor(0.9993)\n",
      "62 tensor(0.9993)\n",
      "63 tensor(0.9997)\n",
      "64 tensor(0.9997)\n",
      "65 tensor(0.9906)\n",
      "66 tensor(0.9917)\n",
      "67 tensor(0.9994)\n",
      "68 tensor(0.9994)\n",
      "69 tensor(0.9997)\n",
      "70 tensor(0.9991)\n",
      "71 tensor(0.9891)\n",
      "72 tensor(0.9912)\n",
      "73 tensor(0.9984)\n",
      "74 tensor(0.9984)\n",
      "75 tensor(0.5553)\n"
     ]
    }
   ],
   "source": [
    "for i,mask in enumerate(masks):\n",
    "    print(i,1-torch.sum(mask)/np.prod(mask.numpy().shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc522b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
